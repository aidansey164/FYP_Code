{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e239d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69cb636",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 1 : Yes (Y)\n",
    "## 2 : Abstain (A)\n",
    "## 3 : No (N)\n",
    "## 8 : Non-participating\n",
    "## 9 : Not eligible to participate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41171b38",
   "metadata": {},
   "source": [
    "# Objective 1. Predicting how a country will vote for a resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cbfc6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\AppData\\Local\\Temp\\ipykernel_40980\\1878795125.py:7: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  votes_df_2 = pd.read_csv(votes_df_2, encoding='latin-1')\n"
     ]
    }
   ],
   "source": [
    "# votes_df = votes_df.loc[votes_df['state_name'] == 'United States of America']\n",
    "\n",
    "# Removing all abstain votes for now https://www.kaggle.com/datasets/unitednations/general-assembly/discussion/29187\n",
    "# votes_df = votes_df.loc[votes_df[\"vote\"] != 2]\n",
    "\n",
    "votes_df_2 = os.path.join(\"undataset2\", 'UNVotes-1.csv')\n",
    "votes_df_2 = pd.read_csv(votes_df_2, encoding='latin-1')\n",
    "\n",
    "\n",
    "votes_df_2 = votes_df_2.loc[votes_df_2['Countryname'] == 'United States of America']\n",
    "votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 2 )]\n",
    "votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 8 )]\n",
    "votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 9 )]\n",
    "\n",
    "df = votes_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37f0fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.783448275862069\n",
      "235 264\n",
      "490 461\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "\t\t\t Naive Bayes report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.73      0.69       235\n",
      "           3       0.86      0.81      0.83       490\n",
      "\n",
      "    accuracy                           0.78       725\n",
      "   macro avg       0.75      0.77      0.76       725\n",
      "weighted avg       0.79      0.78      0.79       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['descr'], df['vote'], test_size=0.15, random_state=27)\n",
    "\n",
    "# Vectorize the text data\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train.values.astype('U').ravel())\n",
    "X_test_vectors = vectorizer.transform(X_test.values.astype('U').ravel())\n",
    "\n",
    "# Train the  Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vectors, y_train)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "y_pred = clf.predict(X_test_vectors)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(y_pred.tolist().count(1), y_test.tolist().count(1))\n",
    "print(y_pred.tolist().count(3), y_test.tolist().count(3))\n",
    "print(y_pred.tolist().count(2), y_test.tolist().count(2))\n",
    "print(y_pred.tolist().count(8), y_test.tolist().count(8))\n",
    "print(y_pred.tolist().count(9), y_test.tolist().count(9))\n",
    "\n",
    "print(\"\\t\\t\\t Naive Bayes report:\\n\",classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93478f4",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b98e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8206896551724138\n",
      "324 264\n",
      "\t\t\t Logistic Regression report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.71      0.78       324\n",
      "           3       0.79      0.91      0.85       401\n",
      "\n",
      "    accuracy                           0.82       725\n",
      "   macro avg       0.83      0.81      0.81       725\n",
      "weighted avg       0.83      0.82      0.82       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "reg = LogisticRegression(class_weight='balanced')\n",
    "reg.fit(X_train_vectors, y_train)\n",
    "y_pred_lr = reg.predict(X_test_vectors)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(y_pred_lr.tolist().count(1), y_test.tolist().count(1))\n",
    "print(\"\\t\\t\\t Logistic Regression report:\\n\",classification_report(y_pred_lr,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750184bf",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "569adbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7655172413793103\n",
      "459 461\n",
      "\t\t\t Decision Tree report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.68      0.68       266\n",
      "           3       0.81      0.82      0.82       459\n",
      "\n",
      "    accuracy                           0.77       725\n",
      "   macro avg       0.75      0.75      0.75       725\n",
      "weighted avg       0.77      0.77      0.77       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train_vectors, y_train)\n",
    "y_pred_dt = dtc.predict(X_test_vectors)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(y_pred_dt.tolist().count(3), y_test.tolist().count(3))\n",
    "print(\"\\t\\t\\t Decision Tree report:\\n\",classification_report(y_pred_dt,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745afd4",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac31b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8275862068965517\n",
      "482 461\n",
      "\t\t\t Random Forest report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.79      0.75       243\n",
      "           3       0.89      0.85      0.87       482\n",
      "\n",
      "    accuracy                           0.83       725\n",
      "   macro avg       0.81      0.82      0.81       725\n",
      "weighted avg       0.83      0.83      0.83       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_vectors, y_train)\n",
    "y_pred_rf = rfc.predict(X_test_vectors)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(y_pred_rf.tolist().count(3), y_test.tolist().count(3))\n",
    "print(\"\\t\\t\\t Random Forest report:\\n\",classification_report(y_pred_rf,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad0488",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56f32342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8593103448275862\n",
      "455 461\n",
      "\t\t\t SVM report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.80      0.81       270\n",
      "           3       0.88      0.89      0.89       455\n",
      "\n",
      "    accuracy                           0.86       725\n",
      "   macro avg       0.85      0.85      0.85       725\n",
      "weighted avg       0.86      0.86      0.86       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train_vectors, y_train)\n",
    "y_pred_svm = svc.predict(X_test_vectors)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(y_pred_svm.tolist().count(3), y_test.tolist().count(3))\n",
    "print(\"\\t\\t\\t SVM report:\\n\",classification_report(y_pred_svm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987486ca",
   "metadata": {},
   "source": [
    "# K Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "669dd06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8275862068965517\n",
      "472 461\n",
      "\t\t\t KNN report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.76       253\n",
      "           3       0.88      0.86      0.87       472\n",
      "\n",
      "    accuracy                           0.83       725\n",
      "   macro avg       0.81      0.82      0.81       725\n",
      "weighted avg       0.83      0.83      0.83       725\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_vectors, y_train)\n",
    "y_pred_knn = knn.predict(X_test_vectors)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(y_pred_knn.tolist().count(3), y_test.tolist().count(3))\n",
    "print(\"\\t\\t\\t KNN report:\\n\",classification_report(y_pred_knn,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fec213b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Accuracies:  {'NaiveBayes': 78.3448275862069, 'LogisticRegression': 82.06896551724138, 'DecisionTree': 76.55172413793103, 'RandomForest': 82.75862068965517, 'SVM': 85.93103448275862, 'KNN': 82.75862068965517}\n",
      "The most accurate model is:  SVM\n"
     ]
    }
   ],
   "source": [
    "list1 = [y_pred,y_pred_lr,y_pred_dt,y_pred_rf,y_pred_svm, y_pred_knn]\n",
    "d =['NaiveBayes','LogisticRegression','DecisionTree','RandomForest','SVM', 'KNN']\n",
    "accuracies={} \n",
    "k=0\n",
    "list2 = []\n",
    "for i in list1:\n",
    "    list2.append(accuracy_score(i,y_test)*100)\n",
    "for i in d:\n",
    "    accuracies[i] = list2[k]\n",
    "    k+=1\n",
    "\n",
    "print(\"All Accuracies: \", accuracies)\n",
    "print(\"The most accurate model is: \", max(accuracies, key=accuracies.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdced97",
   "metadata": {},
   "source": [
    "# Objective 2. Predicting if a resolution will pass or not (accumulate the predicted votes of all countries and compare with the target set resolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ce6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating training set\n",
    "# votes_df_2 = os.path.join(\"undataset2\", 'UNVotes-1.csv')\n",
    "# votes_df_2 = pd.read_csv(votes_df_2, encoding='latin-1')\n",
    "# # votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 2 )]\n",
    "# # votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 8 )]\n",
    "# # votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 9 )]\n",
    "\n",
    "\n",
    "# mask = (votes_df_2['unres'] <= 'R/39/52')\n",
    "# votes_df_2 = votes_df_2.loc[mask]\n",
    "# print(pd.unique(votes_df_2['unres']))\n",
    "\n",
    "# votes_df_italy_test = votes_df_2.loc[votes_df_2['Countryname'] == 'France']\n",
    "# votes_df_ger_test = votes_df_2.loc[votes_df_2['Countryname'] == 'Brazil']\n",
    "# votes_df_esp_test = votes_df_2.loc[votes_df_2['Countryname'] == 'Canada']\n",
    "# votes_df_usa_test = votes_df_2.loc[votes_df_2['Countryname'] == 'United States of America']\n",
    "# votes_df_rus_test = votes_df_2.loc[votes_df_2['Countryname'] == 'Russia']\n",
    "# votes_df_china_test = votes_df_2.loc[votes_df_2['Countryname'] == 'China']\n",
    "# votes_df_ind_test = votes_df_2.loc[votes_df_2['Countryname'] == 'India']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74e7c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def train_model(df):\n",
    "#     # Split the dataset into training and testing sets\n",
    "#     train = df.loc[(df['unres'] <'R/36/172K')]\n",
    "#     test = df.loc[(df['unres'] >='R/36/172K') & (df['unres'] <= 'R/39/52')]\n",
    "    \n",
    "\n",
    "    \n",
    "#     X_train = train['descr']\n",
    "#     X_test = test['descr']\n",
    "#     y_train = train['vote']\n",
    "#     y_test = test['vote']\n",
    "# #     X_train, X_test, y_train, y_test = train_test_split(df['descr'], df['vote'], test_size=0.01, random_state=50)\n",
    "# #     X_train = df['descr'][0:221]\n",
    "# #     X_test = df['vote'][0:221]\n",
    "# #     y_train = df['descr'][0:221]\n",
    "# #     y_test = df['vote'][240:260]\n",
    "#     print(\"X_train: \", len(X_train), \"X_test: \", len(X_test), \"y_train: \", len(y_train), \"y_test: \", len(y_test))\n",
    "\n",
    "#     # Vectorize the text data\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "#     X_train_vectors = vectorizer.fit_transform(X_train.values.astype('U'))\n",
    "#     X_test_vectors = vectorizer.transform(X_test.values.astype('U'))\n",
    "\n",
    "\n",
    "#     # Train the  Naive Bayes classifier\n",
    "#     svc = SVC()\n",
    "#     svc.fit(X_train_vectors, y_train)\n",
    "#     y_pred_svm = svc.predict(X_test_vectors)\n",
    "\n",
    "#     # Evaluate the performance of the classifier\n",
    "#     y_pred = svc.predict(X_test_vectors)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(\"Accuracy:\", accuracy)\n",
    "#     # print(y_pred.tolist().count(1), y_test.tolist().count(1))\n",
    "\n",
    "#     print(\"\\t\\t\\t SVM report:\\n\",classification_report(y_pred,y_test))\n",
    "#     #     predicted = pd.concat([X_test, y_pred])\n",
    "#     return y_pred, y_test, X_test, accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c740ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # t1 = y_pred\n",
    "# # t2 = y_test\n",
    "\n",
    "# t1_ger, t2_ger, t3_ger, t4_ger = train_model(votes_df_ger_test)\n",
    "# t1_italy, t2_italy, t3_italy, t4_italy = train_model(votes_df_italy_test)\n",
    "# t1_esp, t2_esp, t3_esp, t4_esp = train_model(votes_df_esp_test)\n",
    "# t1_usa, t2_usa, t3_usa, t4_usa = train_model(votes_df_usa_test)\n",
    "# t1_ind, t2_ind, t3_ind, t4_ind = train_model(votes_df_ind_test)\n",
    "# t1_china, t2_china, t3_china, t4_china = train_model(votes_df_china_test)\n",
    "# # print(len(votes_df_rus))\n",
    "# # t1_rus, t2_rus, t3_rus, t4_rus = train_model(votes_df_rus)\n",
    "\n",
    "\n",
    "\n",
    "# res = 242\n",
    "\n",
    "# print(len(t3_ger), (len(t3_italy)), (len(t3_esp)), len(t3_usa), (len(t3_ind)), (len(t3_china)))\n",
    "# print(t3_ger[res:res+1], t3_italy[res:res+1], t3_esp[res:res+1], t3_usa[res:res+1], t3_ind[res:res+1], t3_china[res:res+1])\n",
    "# print(t1_ger[res], t1_italy[res], t1_esp[res], t1_usa[res], t1_ind[res], t1_china[res])\n",
    "# print(t2_ger[res:res+1], t2_italy[res:res+1], t2_esp[res:res+1], t2_usa[res:res+1], t2_ind[res:res+1], t2_china[res:res+1])\n",
    "\n",
    "# t2_ger = t2_ger.to_numpy()\n",
    "# t2_italy = t2_italy.to_numpy()\n",
    "# t2_esp = t2_esp.to_numpy()\n",
    "# t2_usa = t2_usa.to_numpy()\n",
    "# t2_ind = t2_ind.to_numpy()\n",
    "# t2_china = t2_china.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = []\n",
    "# y_test = []\n",
    "\n",
    "# y_pred.extend([t1_ger[res], t1_italy[res], t1_esp[res], t1_usa[res], t1_ind[res], t1_china[res]])\n",
    "# y_test.extend([t2_ger[res], t2_italy[res], t2_esp[res], t2_usa[res], t2_ind[res], t2_china[res]])\n",
    "\n",
    "# print(\"Brazil, France, Canada, USA, India, China\")\n",
    "# print(y_pred)\n",
    "# print(y_test)\n",
    "# print(y_pred.count(1), y_pred.count(3))\n",
    "\n",
    "# ## Calculating accuracy\n",
    "# sum(1 for x,y in zip(y_pred,y_test) if x == y) / float(len(y_test))\n",
    "\n",
    "# # votes_df_2= votes_df_2.drop_duplicates(subset=['no','yes'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e1eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
