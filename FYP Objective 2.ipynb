{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1db8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d595c6",
   "metadata": {},
   "source": [
    "# Objective 2. Predicting if a resolution will pass or not as a resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c582a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\AppData\\Local\\Temp\\ipykernel_28328\\2840805932.py:3: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  votes_df_2 = pd.read_csv(votes_df_2, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1.0\n",
      "197        0.0\n",
      "394        1.0\n",
      "591        0.0\n",
      "788        1.0\n",
      "          ... \n",
      "1198256    1.0\n",
      "1198257    1.0\n",
      "1198258    1.0\n",
      "1198259    1.0\n",
      "1198260    1.0\n",
      "Name: pass, Length: 4747, dtype: float64 0          TO ADOPT A CUBAN AMENDMENT TO THE UK PROPOSAL ...\n",
      "197        TO ADOPT A USSR PROPOSAL ADJOURNING DEBATE ON ...\n",
      "394        TO ADOPT THE KOREAN PROPOSAL THAT INVALID BALL...\n",
      "591        TO ADOPT A CUBAN PROPOSAL (A/3-C) THAT AN ITEM...\n",
      "788        TO ADOPT A 6TH COMMITTEE AMENDMENT (A/14) TO T...\n",
      "                                 ...                        \n",
      "1198256    A/73/251 128n - Cooperation between the United...\n",
      "1198257    A/73/251 38 - The situation in the Middle East...\n",
      "1198258    A/73/251 109 - Crime prevention and criminal j...\n",
      "1198259    A/73/251 28a - Implementation of the outcome o...\n",
      "1198260    A/73/251 101aa - Transparency and confidence-b...\n",
      "Name: descr, Length: 4747, dtype: object\n",
      "1.0    4432\n",
      "0.0     315\n",
      "Name: pass, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating training set\n",
    "votes_df_2 = os.path.join(\"undataset2\", 'UNVotes-1.csv')\n",
    "votes_df_2 = pd.read_csv(votes_df_2, encoding='latin-1')\n",
    "\n",
    "votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 2 )]\n",
    "votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 8 )]\n",
    "votes_df_2 = votes_df_2.loc[(votes_df_2[\"vote\"] != 9 )]\n",
    "\n",
    "# Randomly selecting a country to only have one instance of a single resolution\n",
    "votes_df_2 = votes_df_2.loc[votes_df_2['Countryname'] == 'United States of America']\n",
    "\n",
    "df = votes_df_2\n",
    "\n",
    "df.loc[df['yes'] > df['no'], 'pass'] = 1\n",
    "df.loc[df['yes'] < df['no'] ,'pass'] = 0\n",
    "\n",
    "# Removing an possible rows that contain NA values\n",
    "df = df[df['pass'].notna()]\n",
    "\n",
    "print(df['pass'], df['descr'])\n",
    "print(df['pass'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c42f3628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9368421052631579\n",
      "\t\t\t Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.94      0.97       475\n",
      "\n",
      "    accuracy                           0.94       475\n",
      "   macro avg       0.50      0.47      0.48       475\n",
      "weighted avg       1.00      0.94      0.97       475\n",
      "\n",
      "[  2   9  16  22  34  36  54  68  83  87  92 105 108 125 140 142 143 146\n",
      " 147 152 160 161 163 184 196 197 204 210 216 225 229 232 237 238 240 242\n",
      " 254 268 280 288 289 293 294 297 310 311 337 339 348 354 359 401 403 404\n",
      " 407 415 418 419 421 446 461 474]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aidan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aidan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['descr'], df['pass'], test_size=0.10, random_state=27)\n",
    "\n",
    "#Downsampling or upsampling is not applied for this objective to achieve better results\n",
    "\n",
    "# Vectorizing the text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train.values.astype('U'))\n",
    "X_test_vectors = vectorizer.transform(X_test.values.astype('U'))\n",
    "\n",
    "\n",
    "# Training the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vectors, y_train)\n",
    "y_pred = clf.predict(X_test_vectors)\n",
    "\n",
    "# Evaluating the performance of the classifier\n",
    "y_pred = clf.predict(X_test_vectors)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# print(y_pred.tolist().count(1), y_test.tolist().count(1))\n",
    "print(\"\\t\\t\\t Report:\\n\",classification_report(y_pred,y_test))\n",
    "print(np.where(y_pred_lr == 0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d731495",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0b4a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9242105263157895\n",
      "413 445\n",
      "\t\t\t Logistic Regression report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.45      0.61        62\n",
      "         1.0       0.92      1.00      0.96       413\n",
      "\n",
      "    accuracy                           0.92       475\n",
      "   macro avg       0.93      0.72      0.78       475\n",
      "weighted avg       0.92      0.92      0.91       475\n",
      "\n",
      "[  2   9  16  22  34  36  54  68  83  87  92 105 108 125 140 142 143 146\n",
      " 147 152 160 161 163 184 196 197 204 210 216 225 229 232 237 238 240 242\n",
      " 254 268 280 288 289 293 294 297 310 311 337 339 348 354 359 401 403 404\n",
      " 407 415 418 419 421 446 461 474]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg = LogisticRegression(class_weight='balanced')\n",
    "reg.fit(X_train_vectors, y_train)\n",
    "y_pred_lr = reg.predict(X_test_vectors)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(y_pred_lr.tolist().count(1), y_test.tolist().count(1))\n",
    "print(\"\\t\\t\\t Logistic Regression report:\\n\",classification_report(y_pred_lr,y_test))\n",
    "print(np.where(y_pred_lr == 0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269dda0",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8c9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9663157894736842\n",
      "\t\t\t Decision Tree report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.74        32\n",
      "         1.0       0.98      0.98      0.98       443\n",
      "\n",
      "    accuracy                           0.97       475\n",
      "   macro avg       0.87      0.85      0.86       475\n",
      "weighted avg       0.97      0.97      0.97       475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train_vectors, y_train)\n",
    "y_pred_dt = dtc.predict(X_test_vectors)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\t\\t\\t Decision Tree report:\\n\",classification_report(y_pred_dt,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de4be96",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa186653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "462 445\n",
      "\t\t\t Random Forest report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.92      0.56        13\n",
      "         1.0       1.00      0.96      0.98       462\n",
      "\n",
      "    accuracy                           0.96       475\n",
      "   macro avg       0.70      0.94      0.77       475\n",
      "weighted avg       0.98      0.96      0.97       475\n",
      "\n",
      "[ 34  54 140 197 225 238 242 280 310 337 339 348 403]\n",
      "0.0\n",
      "TO ADOPT A USSR AMENDMENT TO JOINT 2ND/3RD COMM. DRAFT RESOL. (A/246), ADDING THE WORDS \\AND ALSO THE RIGHTS TO PRESENT WRITTEN AND VERBAL STATEMENTS TO THE ECONOMIC AND SOCIAL COUNCIL ON ALL MATTERS OF CONCERN FOR THE FEDERATION.\\\\ THE DRAFT R\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_vectors, y_train)\n",
    "y_pred_rf = rfc.predict(X_test_vectors)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(y_pred_rf.tolist().count(1), y_test.tolist().count(1))\n",
    "print(\"\\t\\t\\t Random Forest report:\\n\",classification_report(y_pred_rf,y_test))\n",
    "print(np.where(y_pred_rf == 0)[0])\n",
    "print((y_pred_rf[34]))\n",
    "print((X_test.values[34]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414881b6",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a857e7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9621052631578947\n",
      "0 0\n",
      "\t\t\t SVM report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.88      0.61        16\n",
      "         1.0       1.00      0.97      0.98       459\n",
      "\n",
      "    accuracy                           0.96       475\n",
      "   macro avg       0.73      0.92      0.79       475\n",
      "weighted avg       0.98      0.96      0.97       475\n",
      "\n",
      "[ 34  54 140 142 152 163 184 197 225 229 238 242 280 310 348 403]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train_vectors, y_train)\n",
    "y_pred_svm = svc.predict(X_test_vectors)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(y_pred_svm.tolist().count(3), y_test.tolist().count(3))\n",
    "print(\"\\t\\t\\t SVM report:\\n\",classification_report(y_pred_svm,y_test))\n",
    "print(np.where(y_pred_svm == 0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b7e4d",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b7ca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9642105263157895\n",
      "0 0\n",
      "\t\t\t KNN report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.78      0.68        23\n",
      "         1.0       0.99      0.97      0.98       452\n",
      "\n",
      "    accuracy                           0.96       475\n",
      "   macro avg       0.79      0.88      0.83       475\n",
      "weighted avg       0.97      0.96      0.97       475\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_vectors, y_train)\n",
    "y_pred_knn = knn.predict(X_test_vectors)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(y_pred_knn.tolist().count(3), y_test.tolist().count(3))\n",
    "print(\"\\t\\t\\t KNN report:\\n\",classification_report(y_pred_knn,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080dd52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Accuracies:  {'NaiveBayes': 93.6842105263158, 'LogisticRegression': 92.42105263157895, 'DecisionTree': 96.63157894736842, 'RandomForest': 96.0, 'SVM': 96.21052631578947, 'KNN': 96.42105263157895}\n",
      "The most accurate model is:  DecisionTree\n"
     ]
    }
   ],
   "source": [
    "list1 = [y_pred,y_pred_lr,y_pred_dt,y_pred_rf,y_pred_svm, y_pred_knn]\n",
    "d =['NaiveBayes','LogisticRegression','DecisionTree','RandomForest','SVM', 'KNN']\n",
    "accuracies={} \n",
    "k=0\n",
    "list2 = []\n",
    "for i in list1:\n",
    "    list2.append(accuracy_score(i,y_test)*100)\n",
    "for i in d:\n",
    "    accuracies[i] = list2[k]\n",
    "    k+=1\n",
    "\n",
    "print(\"All Accuracies: \", accuracies)\n",
    "print(\"The most accurate model is: \", max(accuracies, key=accuracies.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce11e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85714f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
